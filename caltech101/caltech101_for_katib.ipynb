{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200311 08:15:56 config:123] Using preprocessor: <kubeflow.fairing.preprocessors.converted_notebook.ConvertNotebookPreprocessor object at 0x7f9140ff88d0>\n",
      "[I 200311 08:15:56 config:125] Using builder: <kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7f90efe3c5c0>\n",
      "[I 200311 08:15:56 config:127] Using deployer: <kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7f90efe3c5c0>\n",
      "[W 200311 08:15:56 append:50] Building image using Append builder...\n",
      "[I 200311 08:15:56 base:105] Creating docker context: /tmp/fairing_context_pa15vx5y\n",
      "[I 200311 08:15:56 converted_notebook:127] Converting caltech101_for_katib.ipynb to caltech101_for_katib.py\n",
      "[I 200311 08:15:56 docker_creds_:234] Loading Docker credentials for repository 'brightfly/tf-fairing:2.0-gpu'\n",
      "[W 200311 08:15:58 append:54] Image successfully built in 2.4560069650033256s.\n",
      "[W 200311 08:15:58 append:94] Pushing image kubeflow-registry.default.svc.cluster.local:30000/caltech-katib-job:5D84029B...\n",
      "[I 200311 08:15:58 docker_creds_:234] Loading Docker credentials for repository 'kubeflow-registry.default.svc.cluster.local:30000/caltech-katib-job:5D84029B'\n",
      "[W 200311 08:15:58 append:81] Uploading kubeflow-registry.default.svc.cluster.local:30000/caltech-katib-job:5D84029B\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:6001e1789921cf851f6fb2e5fe05be70f482fe9c2286f66892fe5a3bc404569c exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:db108ae5c97b9d9b4a6ab30f08b9f00de1a383adb8b2fbdad530e801661c12c5 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:c73ad65f0763fc76b21c650ff9a5d7f4714c30a3dc27f462aa478c829a8efed1 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:9f0a21d58e5dce5512db6d5595c6e9c4ab014917cf0644e2d282b8f5e3f2522a exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:308e2d038b5334fb2ec9872230cfabd52b26102f6c8e0e257f3dcd63cc3b7177 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:74a3420b0759a0426bc7a24daf48c0f376a7e8d293c015e0681884071c3ea0e1 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:d701a76e3193731210c61c838de0c3d8fdc8048b613ca88a58e11dc3223221ec exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:0586a82d62e69da8dab24b635faf9c5da803ff9d208111a25b0e2253c97ec331 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:034db42ae0fa9a91805c16e78f4a6a9d8f5826c95c92713f835b2866333c786c exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:f6490e4900cb64767e994addad4a4329cca4ccfce37a63d21249d89b63ceb478 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:8810fcda1e6e2713f22a64b835ffa1ff15f49257f43dee869abef1929416d362 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:57418a6dc9496eeb6c9324e7bdf6fd48b9e1ac25cb473bf7b71f40d44e2f1e64 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:c4e2f5cde1e102db0e852d5e60ceac5bf377621b397ef3cb7bf1587052ea9520 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:251f5509d51d9e4119d4ffb70d4820f8e2d7dc72ad15df3ebd7cd755539e40fd exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:7d830fc21c34e37fa1d2f683b3392ce76489814b1973691f0593b2ce945b2aca exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:35c102085707f703de2d9eaad8752d6fe1b8f02b5d2149f1d8357c9cc7fb7d0a exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:65881bda3d6dd3c81420e22d3f921824b72ae8c07137aed41d02c640a2f87f04 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:071fd910512489f1cf72f43901d730bfcf302bd46b88924e81f401810bd0e4ce exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:284] Layer sha256:d4026a2c3f0fe2a115daf00a426367cd0021380e1813b3dc362d8a581d66207e pushed.\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:f9e7e7aaea7e58fd475e393007baf0251bad43cccaaef540a365ed1036173ae7 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:180c1b9ae1a5a2a4aba2e08646155b250793be7a97a21556f2c4383f35510f14 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:b0a15f35c371773fb2237091edb340a15cf0e8615de8c9d8c4b8830c35a40265 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:c592fdfb0e51000077def684bbdd097d6d870e62ae94418ba81a3468b03ec833 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:d506ca482a49ec50dabf3d6b43ad6ad14074d7b25b013a122945d81a3fb06746 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:947e0f532378ce4f91ff44af563f21f5679d39a28efa2541594dd3f96730edb0 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:06d09f7e28e650c4614bfeaa1336db8632aa02d48b9ff082d9cdf2edf4204376 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:d1555fb0eeaac2bbfe413314cbbed0dea65a0a72312f29154e21afda1972b0d1 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:7fb8ccf83688665b4137d132962349ffeae8bed7fee8f8b878fee4ecffe1f93d exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:8e829fe70a46e3ac4334823560e98b257234c23629f19f05460e21a453091e6d exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:280] Layer sha256:d12137d65eaa8a740f8bc9419a0fe3e1ba963478fb9179142935e67d667c6f55 exists, skipping\n",
      "[I 200311 08:15:58 docker_session_:284] Layer sha256:937558ca61304ee269bf0b908594edc842a38abbe91c78ae24386fbb2b26e4e9 pushed.\n",
      "[I 200311 08:15:58 docker_session_:334] Finished upload of: kubeflow-registry.default.svc.cluster.local:30000/caltech-katib-job:5D84029B\n",
      "[W 200311 08:15:58 append:99] Pushed image kubeflow-registry.default.svc.cluster.local:30000/caltech-katib-job:5D84029B in 0.10713763200328685s.\n",
      "[W 200311 08:15:58 job:90] The job fairing-job-hw4dz launched.\n",
      "[W 200311 08:15:58 manager:227] Waiting for fairing-job-hw4dz-6qtlb to start...\n",
      "[W 200311 08:15:58 manager:227] Waiting for fairing-job-hw4dz-6qtlb to start...\n",
      "[W 200311 08:15:58 manager:227] Waiting for fairing-job-hw4dz-6qtlb to start...\n",
      "[W 200311 08:15:59 manager:227] Waiting for fairing-job-hw4dz-6qtlb to start...\n",
      "[I 200311 08:16:01 manager:233] Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "2020-03-11 08:16:03.373317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-03-11 08:16:03.500912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:03.501681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:\n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2020-03-11 08:16:03.501849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:03.502428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties:\n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:05.0\n",
      "2020-03-11 08:16:03.502788: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-03-11 08:16:03.504542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-03-11 08:16:03.506285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-03-11 08:16:03.506781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-03-11 08:16:03.509572: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-03-11 08:16:03.511630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-03-11 08:16:03.516671: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-03-11 08:16:03.516808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:03.517506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:03.518110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:03.518766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:03.519382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      " 3129344/87910968 [>.............................] - ETA: 1:50\n",
      "15646720/87910968 [====>.........................] - ETA: 12s\n",
      "27869184/87910968 [========>.....................] - ETA: 80\n",
      "43139072/87910968 [=============>................] - ETA: \n",
      "55541760/87910968 [=================>............] - ETA: 3\n",
      "68026368/87910968 [======================>.......] - ETA: \n",
      "80445440/87910968 [==========================>...] - ETA: \n",
      "87916544/87910968 [==============================] - 8s 0us/step\n",
      "2020-03-11 08:16:19.678446: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-03-11 08:16:19.686446: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2020-03-11 08:16:19.687363: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xa9ba2b0 executing computations on platform Host. Devices:\n",
      "2020-03-11 08:16:19.687394: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "2020-03-11 08:16:20.412599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:20.415816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:20.416858: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xaa54d80 executing computations on platform CUDA. Devices:\n",
      "2020-03-11 08:16:20.416898: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2020-03-11 08:16:20.416910: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "2020-03-11 08:16:20.418515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:20.419226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:\n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2020-03-11 08:16:20.419363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:20.419911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties:\n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:05.0\n",
      "2020-03-11 08:16:20.419968: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-03-11 08:16:20.419981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-03-11 08:16:20.419998: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-03-11 08:16:20.420015: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-03-11 08:16:20.420032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-03-11 08:16:20.420043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-03-11 08:16:20.420057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-03-11 08:16:20.420137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:20.420771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:20.421420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:20.422149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:20.422771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-03-11 08:16:20.422926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-03-11 08:16:20.425789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-11 08:16:20.425832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1\n",
      "2020-03-11 08:16:20.425851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N N\n",
      "2020-03-11 08:16:20.425860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   N N\n",
      "2020-03-11 08:16:20.426479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:20.427296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:20.428174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:20.429053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "2020-03-11 08:16:20.429727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-11 08:16:20.430506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 14202 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to\n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 200, 3) 0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 99, 99, 32)   864         input_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 99, 99, 32)   96          conv2d[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 99, 99, 32)   0           batch_normalization[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 97, 97, 32)   9216        activation[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 97, 97, 32)   96          conv2d_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 97, 97, 32)   0           batch_normalization_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 97, 97, 64)   18432       activation_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 97, 97, 64)   192         conv2d_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 97, 97, 64)   0           batch_normalization_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 48, 48, 64)   0           activation_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 48, 48, 80)   5120        max_pooling2d[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 48, 48, 80)   240         conv2d_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 48, 48, 80)   0           batch_normalization_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 46, 46, 192)  138240      activation_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 46, 46, 192)  576         conv2d_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 46, 46, 192)  0           batch_normalization_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 22, 22, 192)  0           activation_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 22, 22, 64)   12288       max_pooling2d_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 22, 22, 64)   192         conv2d_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 22, 22, 64)   0           batch_normalization_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 22, 22, 48)   9216        max_pooling2d_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 22, 22, 96)   55296       activation_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 22, 22, 48)   144         conv2d_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 22, 22, 96)   288         conv2d_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 22, 22, 48)   0           batch_normalization_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 22, 22, 96)   0           batch_normalization_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 22, 22, 192)  0           max_pooling2d_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 22, 22, 64)   12288       max_pooling2d_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 22, 22, 64)   76800       activation_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 22, 22, 96)   82944       activation_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 22, 22, 32)   6144        average_pooling2d[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 22, 22, 64)   192         conv2d_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 22, 22, 64)   192         conv2d_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 22, 22, 96)   288         conv2d_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 22, 22, 32)   96          conv2d_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 22, 22, 64)   0           batch_normalization_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 22, 22, 64)   0           batch_normalization_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 22, 22, 96)   0           batch_normalization_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 22, 22, 32)   0           batch_normalization_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 22, 22, 256)  0           activation_5[0][0]\n",
      "                                                                 activation_7[0][0]\n",
      "                                                                 activation_10[0][0]\n",
      "                                                                 activation_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 22, 22, 64)   16384       mixed0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 22, 22, 64)   192         conv2d_15[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 22, 22, 64)   0           batch_normalization_15[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 22, 22, 48)   12288       mixed0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 22, 22, 96)   55296       activation_15[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 22, 22, 48)   144         conv2d_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 22, 22, 96)   288         conv2d_16[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 22, 22, 48)   0           batch_normalization_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 22, 22, 96)   0           batch_normalization_16[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 22, 22, 256)  0           mixed0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 22, 22, 64)   16384       mixed0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 22, 22, 64)   76800       activation_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 22, 22, 96)   82944       activation_16[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 22, 22, 64)   16384       average_pooling2d_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 22, 22, 64)   192         conv2d_12[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 22, 22, 64)   192         conv2d_14[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 22, 22, 96)   288         conv2d_17[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 22, 22, 64)   192         conv2d_18[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 22, 22, 64)   0           batch_normalization_12[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 22, 22, 64)   0           batch_normalization_14[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 22, 22, 96)   0           batch_normalization_17[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 22, 22, 64)   0           batch_normalization_18[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 22, 22, 288)  0           activation_12[0][0]\n",
      "                                                                 activation_14[0][0]\n",
      "                                                                 activation_17[0][0]\n",
      "                                                                 activation_18[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 22, 22, 64)   18432       mixed1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 22, 22, 64)   192         conv2d_22[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 22, 22, 64)   0           batch_normalization_22[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 22, 22, 48)   13824       mixed1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 22, 22, 96)   55296       activation_22[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 22, 22, 48)   144         conv2d_20[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 22, 22, 96)   288         conv2d_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 22, 22, 48)   0           batch_normalization_20[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 22, 22, 96)   0           batch_normalization_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 22, 22, 288)  0           mixed1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 22, 22, 64)   18432       mixed1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 22, 22, 64)   76800       activation_20[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 22, 22, 96)   82944       activation_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 22, 22, 64)   18432       average_pooling2d_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 22, 22, 64)   192         conv2d_19[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 22, 22, 64)   192         conv2d_21[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 22, 22, 96)   288         conv2d_24[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 22, 22, 64)   192         conv2d_25[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 22, 22, 64)   0           batch_normalization_19[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 22, 22, 64)   0           batch_normalization_21[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 22, 22, 96)   0           batch_normalization_24[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 22, 22, 64)   0           batch_normalization_25[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 22, 22, 288)  0           activation_19[0][0]\n",
      "                                                                 activation_21[0][0]\n",
      "                                                                 activation_24[0][0]\n",
      "                                                                 activation_25[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 22, 22, 64)   18432       mixed2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 22, 22, 64)   192         conv2d_27[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 22, 22, 64)   0           batch_normalization_27[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 22, 22, 96)   55296       activation_27[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 22, 22, 96)   288         conv2d_28[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 22, 22, 96)   0           batch_normalization_28[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 10, 10, 384)  995328      mixed2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 10, 10, 96)   82944       activation_28[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 10, 10, 384)  1152        conv2d_26[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 10, 10, 96)   288         conv2d_29[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 10, 10, 384)  0           batch_normalization_26[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 10, 10, 96)   0           batch_normalization_29[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 288)  0           mixed2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 10, 10, 768)  0           activation_26[0][0]\n",
      "                                                                 activation_29[0][0]\n",
      "                                                                 max_pooling2d_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 10, 10, 128)  98304       mixed3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 10, 10, 128)  384         conv2d_34[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 10, 10, 128)  0           batch_normalization_34[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 10, 10, 128)  114688      activation_34[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 10, 10, 128)  384         conv2d_35[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 10, 10, 128)  0           batch_normalization_35[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 10, 10, 128)  98304       mixed3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 10, 10, 128)  114688      activation_35[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 10, 10, 128)  384         conv2d_31[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 10, 10, 128)  384         conv2d_36[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 10, 10, 128)  0           batch_normalization_31[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 10, 10, 128)  0           batch_normalization_36[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 10, 10, 128)  114688      activation_31[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 10, 10, 128)  114688      activation_36[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 10, 10, 128)  384         conv2d_32[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 10, 10, 128)  384         conv2d_37[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 10, 10, 128)  0           batch_normalization_32[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 10, 10, 128)  0           batch_normalization_37[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 10, 10, 768)  0           mixed3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 10, 10, 192)  147456      mixed3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 10, 10, 192)  172032      activation_32[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 10, 10, 192)  172032      activation_37[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 10, 10, 192)  147456      average_pooling2d_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 10, 10, 192)  576         conv2d_30[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 10, 10, 192)  576         conv2d_33[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 10, 10, 192)  576         conv2d_38[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 10, 10, 192)  576         conv2d_39[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 10, 10, 192)  0           batch_normalization_30[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 10, 10, 192)  0           batch_normalization_33[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 10, 10, 192)  0           batch_normalization_38[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 10, 10, 192)  0           batch_normalization_39[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 10, 10, 768)  0           activation_30[0][0]\n",
      "                                                                 activation_33[0][0]\n",
      "                                                                 activation_38[0][0]\n",
      "                                                                 activation_39[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 10, 10, 160)  122880      mixed4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 10, 10, 160)  480         conv2d_44[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 10, 10, 160)  0           batch_normalization_44[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 10, 10, 160)  179200      activation_44[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 10, 10, 160)  480         conv2d_45[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 10, 10, 160)  0           batch_normalization_45[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 10, 10, 160)  122880      mixed4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 10, 10, 160)  179200      activation_45[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 10, 10, 160)  480         conv2d_41[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 10, 10, 160)  480         conv2d_46[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 10, 10, 160)  0           batch_normalization_41[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 10, 10, 160)  0           batch_normalization_46[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 10, 10, 160)  179200      activation_41[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 10, 10, 160)  179200      activation_46[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 10, 10, 160)  480         conv2d_42[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 10, 10, 160)  480         conv2d_47[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 10, 10, 160)  0           batch_normalization_42[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 10, 10, 160)  0           batch_normalization_47[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 10, 10, 768)  0           mixed4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 10, 10, 192)  147456      mixed4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 10, 10, 192)  215040      activation_42[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 10, 10, 192)  215040      activation_47[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 10, 10, 192)  147456      average_pooling2d_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 10, 10, 192)  576         conv2d_40[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 10, 10, 192)  576         conv2d_43[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 10, 10, 192)  576         conv2d_48[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 10, 10, 192)  576         conv2d_49[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 10, 10, 192)  0           batch_normalization_40[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 10, 10, 192)  0           batch_normalization_43[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 10, 10, 192)  0           batch_normalization_48[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 10, 10, 192)  0           batch_normalization_49[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 10, 10, 768)  0           activation_40[0][0]\n",
      "                                                                 activation_43[0][0]\n",
      "                                                                 activation_48[0][0]\n",
      "                                                                 activation_49[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 10, 10, 160)  122880      mixed5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 10, 10, 160)  480         conv2d_54[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 10, 10, 160)  0           batch_normalization_54[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 10, 10, 160)  179200      activation_54[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 10, 10, 160)  480         conv2d_55[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 10, 10, 160)  0           batch_normalization_55[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 10, 10, 160)  122880      mixed5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 10, 10, 160)  179200      activation_55[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 10, 10, 160)  480         conv2d_51[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 10, 10, 160)  480         conv2d_56[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 10, 10, 160)  0           batch_normalization_51[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 10, 10, 160)  0           batch_normalization_56[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 10, 10, 160)  179200      activation_51[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 10, 10, 160)  179200      activation_56[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 10, 10, 160)  480         conv2d_52[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 10, 10, 160)  480         conv2d_57[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 10, 10, 160)  0           batch_normalization_52[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 10, 10, 160)  0           batch_normalization_57[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 10, 10, 768)  0           mixed5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 10, 10, 192)  147456      mixed5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 10, 10, 192)  215040      activation_52[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 10, 10, 192)  215040      activation_57[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 10, 10, 192)  147456      average_pooling2d_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 10, 10, 192)  576         conv2d_50[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 10, 10, 192)  576         conv2d_53[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 10, 10, 192)  576         conv2d_58[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 10, 10, 192)  576         conv2d_59[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 10, 10, 192)  0           batch_normalization_50[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 10, 10, 192)  0           batch_normalization_53[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 10, 10, 192)  0           batch_normalization_58[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 10, 10, 192)  0           batch_normalization_59[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 10, 10, 768)  0           activation_50[0][0]\n",
      "                                                                 activation_53[0][0]\n",
      "                                                                 activation_58[0][0]\n",
      "                                                                 activation_59[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 10, 10, 192)  147456      mixed6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 10, 10, 192)  576         conv2d_64[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 10, 10, 192)  0           batch_normalization_64[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 10, 10, 192)  258048      activation_64[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 10, 10, 192)  576         conv2d_65[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 10, 10, 192)  0           batch_normalization_65[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 10, 10, 192)  147456      mixed6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 10, 10, 192)  258048      activation_65[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 10, 10, 192)  576         conv2d_61[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 10, 10, 192)  576         conv2d_66[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 10, 10, 192)  0           batch_normalization_61[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 10, 10, 192)  0           batch_normalization_66[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 10, 10, 192)  258048      activation_61[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 10, 10, 192)  258048      activation_66[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 10, 10, 192)  576         conv2d_62[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 10, 10, 192)  576         conv2d_67[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 10, 10, 192)  0           batch_normalization_62[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 10, 10, 192)  0           batch_normalization_67[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 10, 10, 768)  0           mixed6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 10, 10, 192)  147456      mixed6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 10, 10, 192)  258048      activation_62[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 10, 10, 192)  258048      activation_67[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 10, 10, 192)  147456      average_pooling2d_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 10, 10, 192)  576         conv2d_60[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 10, 10, 192)  576         conv2d_63[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 10, 10, 192)  576         conv2d_68[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 10, 10, 192)  576         conv2d_69[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 10, 10, 192)  0           batch_normalization_60[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 10, 10, 192)  0           batch_normalization_63[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 10, 10, 192)  0           batch_normalization_68[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 10, 10, 192)  0           batch_normalization_69[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 10, 10, 768)  0           activation_60[0][0]\n",
      "                                                                 activation_63[0][0]\n",
      "                                                                 activation_68[0][0]\n",
      "                                                                 activation_69[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 10, 10, 192)  147456      mixed7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 10, 10, 192)  576         conv2d_72[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 10, 10, 192)  0           batch_normalization_72[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 10, 10, 192)  258048      activation_72[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 10, 10, 192)  576         conv2d_73[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 10, 10, 192)  0           batch_normalization_73[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 10, 10, 192)  147456      mixed7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 10, 10, 192)  258048      activation_73[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 10, 10, 192)  576         conv2d_70[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 10, 10, 192)  576         conv2d_74[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 10, 10, 192)  0           batch_normalization_70[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 10, 10, 192)  0           batch_normalization_74[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 4, 4, 320)    552960      activation_70[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 4, 4, 192)    331776      activation_74[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 4, 4, 320)    960         conv2d_71[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 4, 4, 192)    576         conv2d_75[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 4, 4, 320)    0           batch_normalization_71[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 4, 4, 192)    0           batch_normalization_75[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 768)    0           mixed7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 4, 4, 1280)   0           activation_71[0][0]\n",
      "                                                                 activation_75[0][0]\n",
      "                                                                 max_pooling2d_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 4, 4, 448)    573440      mixed8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 4, 4, 448)    1344        conv2d_80[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 4, 4, 448)    0           batch_normalization_80[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 4, 4, 384)    491520      mixed8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 4, 4, 384)    1548288     activation_80[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 4, 4, 384)    1152        conv2d_77[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 4, 4, 384)    1152        conv2d_81[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 4, 4, 384)    0           batch_normalization_77[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 4, 4, 384)    0           batch_normalization_81[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 4, 4, 384)    442368      activation_77[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 4, 4, 384)    442368      activation_77[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 4, 4, 384)    442368      activation_81[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 4, 4, 384)    442368      activation_81[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 4, 4, 1280)   0           mixed8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 4, 4, 320)    409600      mixed8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 4, 4, 384)    1152        conv2d_78[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 4, 4, 384)    1152        conv2d_79[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 4, 4, 384)    1152        conv2d_82[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 4, 4, 384)    1152        conv2d_83[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 4, 4, 192)    245760      average_pooling2d_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 4, 4, 320)    960         conv2d_76[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 4, 4, 384)    0           batch_normalization_78[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 4, 4, 384)    0           batch_normalization_79[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 4, 4, 384)    0           batch_normalization_82[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 4, 4, 384)    0           batch_normalization_83[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 4, 4, 192)    576         conv2d_84[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 4, 4, 320)    0           batch_normalization_76[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 4, 4, 768)    0           activation_78[0][0]\n",
      "                                                                 activation_79[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4, 4, 768)    0           activation_82[0][0]\n",
      "                                                                 activation_83[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 4, 4, 192)    0           batch_normalization_84[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 4, 4, 2048)   0           activation_76[0][0]\n",
      "                                                                 mixed9_0[0][0]\n",
      "                                                                 concatenate[0][0]\n",
      "                                                                 activation_84[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 4, 4, 448)    917504      mixed9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 4, 4, 448)    1344        conv2d_89[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 4, 4, 448)    0           batch_normalization_89[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 4, 4, 384)    786432      mixed9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 4, 4, 384)    1548288     activation_89[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 4, 4, 384)    1152        conv2d_86[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 4, 4, 384)    1152        conv2d_90[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 4, 4, 384)    0           batch_normalization_86[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 4, 4, 384)    0           batch_normalization_90[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 4, 4, 384)    442368      activation_86[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 4, 4, 384)    442368      activation_86[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 4, 4, 384)    442368      activation_90[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 4, 4, 384)    442368      activation_90[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 4, 4, 2048)   0           mixed9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 4, 4, 320)    655360      mixed9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 4, 4, 384)    1152        conv2d_87[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 4, 4, 384)    1152        conv2d_88[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 4, 4, 384)    1152        conv2d_91[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 4, 4, 384)    1152        conv2d_92[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 4, 4, 192)    393216      average_pooling2d_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 4, 4, 320)    960         conv2d_85[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 4, 4, 384)    0           batch_normalization_87[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 4, 4, 384)    0           batch_normalization_88[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 4, 4, 384)    0           batch_normalization_91[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 4, 4, 384)    0           batch_normalization_92[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 4, 4, 192)    576         conv2d_93[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 4, 4, 320)    0           batch_normalization_85[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 4, 4, 768)    0           activation_87[0][0]\n",
      "                                                                 activation_88[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4, 4, 768)    0           activation_91[0][0]\n",
      "                                                                 activation_92[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 4, 4, 192)    0           batch_normalization_93[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 4, 4, 2048)   0           activation_85[0][0]\n",
      "                                                                 mixed9_1[0][0]\n",
      "                                                                 concatenate_1[0][0]\n",
      "                                                                 activation_93[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 2048)         0           mixed10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "fully (Dense)                   (None, 1024)         2098176     global_max_pooling2d[0][0]\n",
      "WARNING:tensorflow:From /app/caltech101_for_katib.py:74: multi_gpu_model (from tensorflow.python.keras.utils.multi_gpu_utils) is deprecated and will be removed after 2020-04-01.\n",
      "Instructions for updating:\n",
      "Use `tf.distribute.MirroredStrategy` instead.\n",
      "2020-03-11 08:17:07.267778: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-03-11 08:17:08.136726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-35a39e8b20a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mipy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mfairing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_preprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mfairing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCaltech101\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kubeflow/fairing/config.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mpod_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_pod_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mdeployer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpod_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kubeflow/fairing/deployers/job/job.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, pod_spec)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_log\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kubeflow/fairing/deployers/job/job.py\u001b[0m in \u001b[0;36mget_logs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                          container=\"fairing-job\")\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kubeflow/fairing/kubernetes/manager.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(self, name, namespace, selectors, container, follow)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_STREAM_BYTES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \"\"\"\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, Input, Activation, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import Callback\n",
    "from tensorflow.python.keras.utils import multi_gpu_model\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "\n",
    "class Caltech101(object):\n",
    "    def run(self):\n",
    "        tf.compat.v1.disable_eager_execution()\n",
    "        # 입력 값을 받게 추가합니다.\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--learning_rate', required=False, type=float, default=0.001)\n",
    "        parser.add_argument('--dropout_rate', required=False, type=float, default=0.2)\n",
    "        parser.add_argument('--batch_size', required=False, type=int, default=16)    \n",
    "        parser.add_argument('--epoch', required=False, type=int, default=10)            \n",
    "        # relu, sigmoid, softmax, tanh\n",
    "        parser.add_argument('--act', required=False, type=str, default='relu')        \n",
    "      \n",
    "\n",
    "        args = parser.parse_args()          \n",
    "        \n",
    "        input = Input(shape=(200, 200, 3))\n",
    "        model = InceptionV3(input_tensor=input, include_top=False, weights='imagenet', pooling='max')\n",
    "\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        input_image_size = (200, 200)\n",
    "\n",
    "        x = model.output\n",
    "        x = Dense(1024, name='fully')(x)\n",
    "        x = Dropout(args.dropout_rate)(x)        \n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(args.act)(x)\n",
    "        x = Dense(512)(x)\n",
    "        x = Dropout(args.dropout_rate)(x)          \n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(args.act)(x)\n",
    "        x = Dense(101, activation='softmax', name='softmax')(x)\n",
    "        model = Model(model.input, x)\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        train_datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2)\n",
    "        batch_size = args.batch_size\n",
    "\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            '/result/caltech101',\n",
    "            target_size=input_image_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='training')\n",
    "\n",
    "        validation_generator = train_datagen.flow_from_directory(\n",
    "            '/result/caltech101',\n",
    "            target_size=input_image_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='validation')\n",
    "        model = multi_gpu_model(model, gpus=2)\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(lr=args.learning_rate),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['acc'])\n",
    "\n",
    "        early_stopping = EarlyStopping(patience=20, mode='auto', monitor='val_acc')\n",
    "        hist = model.fit_generator(train_generator,\n",
    "                                      verbose=0,\n",
    "                                      steps_per_epoch=train_generator.samples // batch_size,\n",
    "                                      validation_data = validation_generator,\n",
    "                                      epochs=args.epoch,\n",
    "                                      callbacks=[early_stopping, KatibMetricLog()])\n",
    "        \n",
    "class KatibMetricLog(Callback):\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        print(\"batch=\" + str(batch),\n",
    "              \"accuracy=\" + str(logs.get('acc')),\n",
    "              \"loss=\" + str(logs.get('loss')))\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        print(\"epoch \" + str(epoch) + \":\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        print(\"Validation-accuracy=\" + str(logs.get('val_acc')),\n",
    "              \"Validation-loss=\" + str(logs.get('val_loss')))\n",
    "        return      \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    if os.getenv('FAIRING_RUNTIME', None) is None:\n",
    "        from kubeflow import fairing\n",
    "        from kubeflow.fairing.kubernetes import utils as k8s_utils\n",
    "        DOCKER_REGISTRY = 'kubeflow-registry.default.svc.cluster.local:30000'\n",
    "        fairing.config.set_builder(\n",
    "            'append',\n",
    "            image_name='caltech-katib-job',\n",
    "            base_image='brightfly/tf-fairing:2.0-gpu',\n",
    "            registry=DOCKER_REGISTRY,\n",
    "            push=True)\n",
    "        # cpu 1, memory 1GiB\n",
    "        fairing.config.set_deployer('job',\n",
    "                                    namespace='dudaji',\n",
    "                                    pod_spec_mutators=[\n",
    "                                    k8s_utils.mounting_pvc(pvc_name=\"caltech101\", \n",
    "                                                          pvc_mount_path=\"/result\")]\n",
    "                                    )\n",
    "        # python3\n",
    "        import IPython\n",
    "        ipy = IPython.get_ipython()\n",
    "        if ipy is None:\n",
    "            fairing.config.set_preprocessor('python', input_files=[__file__])        \n",
    "        fairing.config.run()\n",
    "    else:\n",
    "        train = Caltech101()\n",
    "        train.run()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                COMPLETIONS   DURATION   AGE\n",
      "fairing-job-hw4dz   0/1           84s        84s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job.batch \"fairing-job-hw4dz\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete job fairing-job-hw4dz   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
